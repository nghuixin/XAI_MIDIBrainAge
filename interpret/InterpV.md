Medical imaging interpretability

Visualizing saliency
Visualizing gradient images corresponding to increasing / decreasing age on a particular image input
Class activation maps – modified for regression - Diabetic Retinopathy Detection via Deep Convolutional Networks for Discriminative Localization and Visual Explanation  


Visualizing model activations
Understanding Neural Networks Through Deep Visualization 
Feature Visualization 



Dimensionality reduction
Use t-sne / UMAP / PCA to reduce dimensions of network activations (maybe last layer?) and visualize how input brain scans are distributed in the low dimensional space



Broad overviews of interpreting ML models
The Building Blocks of Interpretability
How to Explain the Prediction of a Machine Learning Model? 
Interpretation and visualization techniques for deep learning models in medical imaging 

https://www.sciencedirect.com/science/article/pii/S1053811922000015#sec0027
https://www.pnas.org/doi/epdf/10.1073/pnas.2214634120


People to reach out to:
Viren Jain (Google, https://virenjain.org/), Sebastian Seung (https://seunglab.org/)  

COVID-DenseNet: A Deep Learning Architecture to Detect COVID-19 from Chest Radiology Images – paper has a lot of good related work on using densenets or computer vision for medical imaging. Worth reaching out to these folks for thoughts on open issues in visualization for med imaging or take inspiration from any of the related work for new visualization techniques
