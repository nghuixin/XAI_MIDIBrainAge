{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LRP-0 (LRP-Zero) Rule:\n",
    "\n",
    "This rule is often applied to fully connected layers with ReLU activations. It propagates relevance to the input neurons based on the proportion of the positive contributions of each neuron to the layer's output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrp_zero(R, layer):\n",
    "    V = torch.clamp(layer.weight, min=0)\n",
    "    Z = torch.mm(layer.input, V.t()) + 1e-9  # Stabilize division by small constant\n",
    "    S = R / Z\n",
    "    C = torch.mm(S, V)\n",
    "    R_next = layer.input * C\n",
    "    return R_next\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LRP-ε (Epsilon) Rule:\n",
    "\n",
    "The LRP-ε rule adds a small positive term (epsilon) to the denominator during the relevance propagation to stabilize the division, especially when the contributions in the denominator are close to zero. This prevents the amplification of contributions from low-activation neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrp_epsilon(R, layer, epsilon=0.01):\n",
    "    Z = torch.mm(layer.input, layer.weight.t()) + epsilon  # Add epsilon for numerical stability\n",
    "    S = R / Z\n",
    "    C = torch.mm(S, layer.weight)\n",
    "    R_next = layer.input * C\n",
    "    return R_next\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LRP-γ (Gamma) Rule:\n",
    "\n",
    "The LRP-γ rule introduces a parameter gamma that amplifies the contribution of positive activations. It is designed to put more emphasis on neurons that have a stronger positive influence on the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrp_gamma(R, layer, gamma=0.1):\n",
    "    V = torch.clamp(layer.weight, min=0) * (1 + gamma) - torch.clamp(layer.weight, max=0) * gamma\n",
    "    Z = torch.mm(layer.input, V.t()) + 1e-9  # Stabilize division by small constant\n",
    "    S = R / Z\n",
    "    C = torch.mm(S, V)\n",
    "    R_next = layer.input * C\n",
    "    return R_next\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LRP-αβ (Alpha Beta) Rule:\n",
    "\n",
    "This rule uses two parameters, alpha and beta, to separately treat positive and negative contributions during relevance propagation. The alpha parameter scales the positive contributions, while beta scales the negative ones. Typically, alpha is set to 1 and beta to 0, ensuring that only positive contributions are considered, which is useful for networks with mixed activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrp_alpha_beta(R, layer, alpha=1, beta=0):\n",
    "    V_pos = torch.clamp(layer.weight, min=0) * alpha\n",
    "    V_neg = torch.clamp(layer.weight, max=0) * beta\n",
    "    Z = torch.mm(layer.input, (V_pos - V_neg).t()) + 1e-9  # Stabilize division by small constant\n",
    "    S = R / Z\n",
    "    C_pos = torch.mm(S, V_pos)\n",
    "    C_neg = torch.mm(S, V_neg)\n",
    "    R_next = layer.input * (C_pos + C_neg)\n",
    "    return R_next\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LRP-Flat (Flat) Rule:\n",
    "\n",
    "The LRP-Flat rule distributes relevance equally among all contributing neurons, regardless of their individual contribution. This rule is often used as a baseline or for comparison with other rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrp_flat(R, layer):\n",
    "    contribution = torch.ones_like(layer.weight)\n",
    "    Z = torch.mm(layer.input, contribution.t()) + 1e-9  # Stabilize division by small constant\n",
    "    S = R / Z\n",
    "    C = torch.mm(S, contribution)\n",
    "    R_next = layer.input * C\n",
    "    return R_next\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LRP-Composite Rule:\n",
    "\n",
    "Composite rules combine different LRP rules for different layers of the network. For example, one might use the LRP-ε rule for the first few layers and the LRP-γ rule for the last few layers, depending on the characteristics of the network and the desired explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrp_composite(R, layer, rule_for_layer):\n",
    "    # Apply different rules based on the layer type or order\n",
    "    if rule_for_layer == 'epsilon':\n",
    "        return lrp_epsilon(R, layer)\n",
    "    elif rule_for_layer == 'gamma':\n",
    "        return lrp_gamma(R, layer)\n",
    "    # Add other conditions as necessary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LRP-w^2 Rule:\n",
    "\n",
    "This rule considers the square of the weights as the relevance criteria, emphasizing the importance of the weight's magnitude, independent of the activation sign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrp_w_square(R, layer):\n",
    "    W_square = torch.pow(layer.weight, 2)\n",
    "    Z = torch.mm(layer.input, W_square.t()) + 1e-9  # Stabilize division by small constant\n",
    "    S = R / Z\n",
    "    C = torch.mm(S, W_square)\n",
    "    R_next = layer.input * C\n",
    "    return R_next\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LRP-z^+ Rule:\n",
    "\n",
    "Similar to LRP-0 but only considers the positive part of the z contribution, which is the weighted sum of the activations from the lower layer plus the bias term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrp_z_plus(R, layer):\n",
    "    V = torch.clamp(layer.weight, min=0)\n",
    "    Z = torch.mm(layer.input, V.t()) + 1e-9  # Stabilize division by small constant\n",
    "    S = R / Z\n",
    "    C = torch.mm(S, V)\n",
    "    R_next = layer.input * C\n",
    "    return R_next\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
